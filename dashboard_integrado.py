# dashboard_integrado.py
import os
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from statsmodels.tsa.statespace.sarimax import SARIMAX
from urllib.parse import unquote

# --- Configura√ß√µes da P√°gina ---
st.set_page_config(layout="wide", page_title="An√°lise Avan√ßada de Continuidade - ANEEL")


# --- Fun√ß√µes de L√≥gica e Carregamento de Dados ---
@st.cache_data
def obter_lista_distribuidoras(path='dados_processados'):
    """
    Usa os.walk para varrer a estrutura de diret√≥rios e encontrar as pastas
    de parti√ß√£o da distribuidora de forma expl√≠cita e robusta.
    """
    distribuidoras = set()
    try:
        if not os.path.isdir(path):
            st.error(f"A pasta '{path}' n√£o foi encontrada. Execute o '1_processar_dados.py' primeiro.")
            return []

        for root, dirs, files in os.walk(path):
            for dirname in dirs:
                if dirname.startswith('Distribuidora='):
                    nome_bruto_codificado = dirname.split('=', 1)[1]
                    nome_decodificado = unquote(nome_bruto_codificado)
                    nome_limpo = nome_decodificado.strip()
                    if nome_limpo:
                        distribuidoras.add(nome_limpo)

        if not distribuidoras:
            st.warning(
                "Nenhuma parti√ß√£o de distribuidora foi encontrada na pasta 'dados_processados'. Verifique se o pipeline foi executado corretamente.")
            return []

        return sorted(list(distribuidoras))

    except Exception as e:
        st.error(f"Ocorreu um erro ao ler a estrutura de pastas em '{path}'. Detalhes: {e}")
        return []


@st.cache_data
def carregar_dados_distribuidora(distribuidora):
    """
    Carrega dados de uma distribuidora espec√≠fica do Data Lakehouse (Delta/Parquet).
    O filtro de parti√ß√£o torna esta opera√ß√£o extremamente r√°pida.
    """
    try:
        df = pd.read_parquet('dados_processados', filters=[('Distribuidora', '==', distribuidora)])
        df['Data'] = pd.to_datetime(df['Ano'].astype(str) + '-' + df['Mes'].astype(str))
        return df
    except Exception as e:
        st.error(f"N√£o foi poss√≠vel carregar os dados para {distribuidora}. Detalhes: {e}")
        return pd.DataFrame()


# --- Layout da Aplica√ß√£o ---
st.sidebar.title("Navega√ß√£o e Filtros")

tipo_analise = st.sidebar.radio(
    "Selecione o Tipo de An√°lise:",
    ["Sobre o Projeto", "Vis√£o Geral (KPIs)", "An√°lise de Conjuntos", "S√©ries Temporais e Previs√µes",
     "Simula√ß√£o de Cen√°rio"]
)

if tipo_analise == "Sobre o Projeto":
    st.title("Sobre o Projeto de An√°lise de Indicadores da ANEEL")
    st.info(
        "Este dashboard √© o resultado de um pipeline de dados para an√°lise de indicadores de continuidade da ANEEL.")
    st.markdown("""
    ### Arquitetura e Boas Pr√°ticas Implementadas:
    - **Pipeline de Dados Unificado:** O processo em `processar_dados.py` extrai dados de arquivos locais (`dados_brutos/`) e da API da ANEEL.
    - **Configura√ß√£o Centralizada:** Todas as configura√ß√µes (caminhos, URLs) est√£o no arquivo `config.yaml`, facilitando a manuten√ß√£o.
    - **Logging:** As execu√ß√µes do pipeline geram logs detalhados na pasta `logs/`, em vez de usar `print()`.
    - **Qualidade de Dados:** A biblioteca `Pandera` √© usada para validar o esquema e a qualidade dos dados antes de serem salvos, garantindo a confiabilidade da an√°lise.
    - **Data Lakehouse com Delta Lake:** Os dados s√£o armazenados na pasta `dados_processados` no formato Delta Lake, o que garante transa√ß√µes ACID, confiabilidade e performance.
    - **Dashboard Interativo:** Constru√≠do com Streamlit para explora√ß√£o din√¢mica dos dados.
    - **Gerenciamento de Depend√™ncias:** O arquivo `requirements.txt` garante a reprodutibilidade do ambiente.
    """)
    st.markdown("---")
    st.write("Selecione uma das op√ß√µes de an√°lise na barra lateral para come√ßar.")

else:
    lista_distribuidoras = obter_lista_distribuidoras()
    if lista_distribuidoras:
        distribuidora_selecionada = st.sidebar.selectbox(
            "Selecione a Distribuidora:", lista_distribuidoras,
            index=lista_distribuidoras.index('CRELUZ-D') if 'CRELUZ-D' in lista_distribuidoras else 0
        )
        df_distribuidora = carregar_dados_distribuidora(distribuidora_selecionada)
        if not df_distribuidora.empty:
            indicadores_disponiveis = [col for col in ['DEC', 'FEC', 'DIC', 'FIC'] if
                                       col in df_distribuidora.columns and df_distribuidora[col].sum() > 0]
            indicador_selecionado = st.sidebar.selectbox("Selecione o Indicador:", indicadores_disponiveis)
            anos_disponiveis = sorted(df_distribuidora['Ano'].unique(), reverse=True)
            ano_selecionado = st.sidebar.selectbox("Selecione o Ano:", anos_disponiveis)

            st.title(f"Dashboard ANEEL: {distribuidora_selecionada}")
            st.subheader(f"{tipo_analise} - Indicador {indicador_selecionado}")
            df_analise_ano = df_distribuidora[df_distribuidora['Ano'] == ano_selecionado].copy()

            if tipo_analise == "Vis√£o Geral (KPIs)":
                st.markdown(f"### Desempenho em {ano_selecionado}")
                valores_sem_zero = df_analise_ano[df_analise_ano[indicador_selecionado] > 0][indicador_selecionado]
                melhor_valor = valores_sem_zero.min()
                if pd.isna(melhor_valor):
                    melhor_valor = 0.0

                col1, col2, col3 = st.columns(3)
                col1.metric("Valor M√©dio", f"{df_analise_ano[indicador_selecionado].mean():.2f}")
                col2.metric("Pior Valor (M√°x)", f"{df_analise_ano[indicador_selecionado].max():.2f}")
                col3.metric("Melhor Valor (M√≠n)", f"{melhor_valor:.2f}")

                st.markdown("### Evolu√ß√£o Hist√≥rica do Indicador")
                evolucao_anual = df_distribuidora.groupby('Ano')[indicador_selecionado].mean().reset_index()
                fig = px.line(evolucao_anual, x='Ano', y=indicador_selecionado,
                              title=f'M√©dia Anual de {indicador_selecionado}', markers=True)
                st.plotly_chart(fig, use_container_width=True)

            elif tipo_analise == "An√°lise de Conjuntos":
                ranking_piores = df_analise_ano.groupby(['NomConjunto', 'ConjuntoID'])[
                    indicador_selecionado].mean().sort_values(ascending=False).reset_index()

                st.markdown(f"### Piores Conjuntos em {ano_selecionado}")
                fig_piores = px.bar(ranking_piores.head(20), x=indicador_selecionado, y='NomConjunto', orientation='h',
                                    title=f"Top 20 Piores Conjuntos por {indicador_selecionado}",
                                    labels={indicador_selecionado: f'Valor M√©dio de {indicador_selecionado}',
                                            'NomConjunto': 'Conjunto'})
                fig_piores.update_layout(yaxis={'categoryorder': 'total descending'}, height=500, margin=dict(l=300))
                st.plotly_chart(fig_piores, use_container_width=True, key="piores_conjuntos_bar")

                with st.expander("üîç An√°lise de Anomalias Estat√≠sticas"):
                    st.info(
                        "Esta an√°lise destaca conjuntos cujo desempenho no ano selecionado foi estatisticamente incomum em compara√ß√£o com seu pr√≥prio hist√≥rico.")
                    stats_historico = df_distribuidora.groupby('ConjuntoID')[indicador_selecionado].agg(
                        ['mean', 'std']).reset_index()
                    stats_historico.rename(columns={'mean': 'MediaHistorica', 'std': 'DesvioPadraoHistorico'},
                                           inplace=True)
                    stats_historico = stats_historico.fillna(0)

                    df_anomalia = pd.merge(df_analise_ano, stats_historico, on='ConjuntoID')
                    epsilon = 1e-6
                    df_anomalia['Z_Score'] = (df_anomalia[indicador_selecionado] - df_anomalia['MediaHistorica']) / (
                                df_anomalia['DesvioPadraoHistorico'] + epsilon)

                    anomalias = df_anomalia[df_anomalia['Z_Score'].abs() > 2.5].sort_values('Z_Score', ascending=False)
                    if not anomalias.empty:
                        st.write("Conjuntos com desempenho estatisticamente an√¥malo (pior ou melhor que sua m√©dia):")
                        st.dataframe(anomalias[['NomConjunto', indicador_selecionado, 'MediaHistorica', 'Z_Score']])
                    else:
                        st.success("Nenhuma anomalia estat√≠stica significativa encontrada para o ano selecionado.")

                st.markdown("### Compara√ß√£o Hist√≥rica do Pior Conjunto")
                if not ranking_piores.empty:
                    pior_conjunto_nome = ranking_piores['NomConjunto'].iloc[0]
                    pior_conjunto_id = ranking_piores['ConjuntoID'].iloc[0]
                    st.write(
                        f"Analisando a evolu√ß√£o para o pior conjunto de {ano_selecionado}: **{pior_conjunto_nome}**")
                    df_pior_conjunto = df_distribuidora[df_distribuidora['ConjuntoID'] == pior_conjunto_id]
                    evolucao_pior = df_pior_conjunto.groupby('Ano')[indicador_selecionado].mean().reset_index()
                    fig2 = px.bar(evolucao_pior, x='Ano', y=indicador_selecionado,
                                  title=f"Evolu√ß√£o Hist√≥rica de {indicador_selecionado} para {pior_conjunto_nome}")
                    st.plotly_chart(fig2, use_container_width=True, key="pior_conjunto_hist")

                st.markdown("---")
                ranking_melhores = df_analise_ano.groupby(['NomConjunto', 'ConjuntoID'])[
                    indicador_selecionado].mean().sort_values(ascending=True).reset_index()
                st.markdown(f"### Melhores Conjuntos em {ano_selecionado}")
                fig_melhores = px.bar(ranking_melhores.head(20), x=indicador_selecionado, y='NomConjunto',
                                      orientation='h',
                                      title=f"Top 20 Melhores Conjuntos por {indicador_selecionado}",
                                      labels={indicador_selecionado: f'Valor M√©dio de {indicador_selecionado}',
                                              'NomConjunto': 'Conjunto'})
                fig_melhores.update_layout(yaxis={'categoryorder': 'total ascending'}, height=500, margin=dict(l=300))
                st.plotly_chart(fig_melhores, use_container_width=True, key="melhores_conjuntos_bar")

                st.markdown("### Compara√ß√£o Hist√≥rica do Melhor Conjunto")
                if not ranking_melhores.empty:
                    melhor_conjunto_nome = ranking_melhores['NomConjunto'].iloc[0]
                    melhor_conjunto_id = ranking_melhores['ConjuntoID'].iloc[0]
                    st.write(
                        f"Analisando a evolu√ß√£o para o melhor conjunto de {ano_selecionado}: **{melhor_conjunto_nome}**")
                    df_melhor_conjunto = df_distribuidora[df_distribuidora['ConjuntoID'] == melhor_conjunto_id]
                    evolucao_melhor = df_melhor_conjunto.groupby('Ano')[indicador_selecionado].mean().reset_index()
                    fig_melhor2 = px.bar(evolucao_melhor, x='Ano', y=indicador_selecionado,
                                         title=f"Evolu√ß√£o Hist√≥rica de {indicador_selecionado} para {melhor_conjunto_nome}")
                    st.plotly_chart(fig_melhor2, use_container_width=True, key="melhor_conjunto_hist")

                st.markdown("### Ranking Completo dos Conjuntos (Ordenado do Pior ao Melhor)")
                st.dataframe(ranking_piores, use_container_width=True)

            elif tipo_analise == "S√©ries Temporais e Previs√µes":
                ts_data = df_distribuidora.groupby('Data')[indicador_selecionado].mean().resample('MS').asfreq()
                ts_data.fillna(ts_data.mean(), inplace=True)
                st.markdown("### S√©rie Temporal Mensal Hist√≥rica")
                fig_hist = px.line(ts_data, x=ts_data.index, y=ts_data.values, labels={'x': 'Data', 'y': 'Valor M√©dio'},
                                   title=f"M√©dia Mensal de {indicador_selecionado}")
                st.plotly_chart(fig_hist, use_container_width=True)
                st.markdown("### Previs√µes para os Pr√≥ximos 12 Meses")
                if len(ts_data.dropna()) < 24:
                    st.warning(
                        "N√£o h√° dados hist√≥ricos suficientes (m√≠nimo de 24 meses) para gerar uma previs√£o confi√°vel.")
                elif st.button("Gerar Previs√µes (Pode levar um minuto)"):
                    try:
                        with st.spinner("Treinando modelo SARIMAX e gerando previs√£o..."):
                            model_sarimax = SARIMAX(ts_data, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12),
                                                    enforce_stationarity=False, enforce_invertibility=False)
                            results = model_sarimax.fit(disp=False)
                            forecast_object = results.get_forecast(steps=12)
                            forecast_ci = forecast_object.conf_int()
                            forecast_mean = forecast_object.predicted_mean
                            fig_forecast = go.Figure()
                            fig_forecast.add_trace(
                                go.Scatter(x=ts_data.index, y=ts_data.values, mode='lines', name='Hist√≥rico'))
                            fig_forecast.add_trace(
                                go.Scatter(x=forecast_mean.index, y=forecast_mean.values, mode='lines', name='Previs√£o',
                                           line=dict(dash='dash')))
                            fig_forecast.add_trace(
                                go.Scatter(x=forecast_ci.index, y=forecast_ci.iloc[:, 0], fill=None, mode='lines',
                                           line_color='rgba(255,255,255,0)', showlegend=False))
                            fig_forecast.add_trace(
                                go.Scatter(x=forecast_ci.index, y=forecast_ci.iloc[:, 1], fill='tonexty',
                                           fillcolor='rgba(0,176,246,0.4)', mode='lines',
                                           line_color='rgba(255,255,255,0)', name='Intervalo de Confian√ßa'))
                            fig_forecast.update_layout(
                                title=f"Hist√≥rico vs. Previs√£o SARIMAX para {indicador_selecionado}",
                                xaxis_title="Data", yaxis_title=f"Valor do {indicador_selecionado}")
                            st.plotly_chart(fig_forecast, use_container_width=True)
                    except Exception as e:
                        st.error(f"Ocorreu um erro ao gerar a previs√£o: {e}")
                        st.info(
                            "Isso pode acontecer se os dados hist√≥ricos n√£o forem adequados para o modelo (ex: pouca varia√ß√£o, muitos zeros).")

            elif tipo_analise == "Simula√ß√£o de Cen√°rio":
                st.markdown("### An√°lise de Cen√°rio 'What-if'")
                st.write(
                    "Insira um valor para o indicador e veja qual seria sua posi√ß√£o em rela√ß√£o aos dados hist√≥ricos da distribuidora.")
                valor_simulado = st.number_input(f"Insira um valor para {indicador_selecionado}:",
                                                 value=float(df_distribuidora[indicador_selecionado].mean()), step=1.0,
                                                 format="%.2f")
                if st.button("Analisar Cen√°rio"):
                    valores_historicos = df_distribuidora[indicador_selecionado].dropna()
                    percentil = (valores_historicos < valor_simulado).mean() * 100
                    st.success(
                        f"Um valor de **{valor_simulado:.2f}** seria melhor que **{percentil:.2f}%** dos registros hist√≥ricos para esta distribuidora.")

            st.sidebar.markdown("---")
            st.sidebar.subheader("Exportar Dados")
            csv = df_distribuidora.to_csv(index=False).encode('utf-8')
            st.sidebar.download_button(
                label="Baixar dados da distribuidora (.csv)",
                data=csv,
                file_name=f"{distribuidora_selecionada}_dados_completos.csv",
                mime='text/csv',
            )